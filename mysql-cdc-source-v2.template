{
  "template_id": "MySqlCdcSourceV2",
  "connector_type": "SOURCE",
  "connector.class": "io.debezium.connector.v2.mysql.MySqlConnectorV2",
  "name": "{{.logicalClusterId}}",
  "imports": [
    "common-debezium-source-v2",
    "common",
    "common-kafka-connectivity",
    "common-source",
    "schema-registry",
    "source-connector-output-data-format",
    "output-key-format-debezium-source",
    "csfle-source"
  ],
  "group_order": [
    "How should we connect to your data?",
    "Kafka Cluster credentials",
    "How should we connect to your database?",
    "CSFLE",
    "Output messages",
    "How should we name your topic(s)?",
    "Database config",
    "Connector config",
    "Schema Config",
    "How should we handle data types?",
    "Number of tasks for this connector",
    "Additional Configs"
  ],
  "config_defs": [
    {
      "name": "database.hostname",
      "required": true,
      "documentation": "IP address or hostname of the MySQL database server.",
      "metadata": {
        "page": "AUTHENTICATION",
        "order_in_page": 1,
        "group_name": "How should we connect to your database?"
      }
    },
    {
      "name": "database.port",
      "required": true,
      "documentation": "Port number of the MySQL database server.",
      "metadata": {
        "page": "AUTHENTICATION",
        "order_in_page": 2,
        "group_name": "How should we connect to your database?"
      }
    },
    {
      "name": "database.user",
      "required": true,
      "documentation": "The name of the MySQL database user that has the required authorization.",
      "metadata": {
        "page": "AUTHENTICATION",
        "order_in_page": 3,
        "group_name": "How should we connect to your database?"
      }
    },
    {
      "name": "database.password",
      "required": true,
      "documentation": "Password for the MySQL database user that has the required authorization.",
      "metadata": {
        "page": "AUTHENTICATION",
        "order_in_page": 4,
        "group_name": "How should we connect to your database?"
      }
    },
    {
      "name": "database.ssl.mode",
      "type": "STRING",
      "required": false,
      "default_value": "preferred",
      "importance": "HIGH",
      "group": "How should we connect to your database?",
      "order_in_group": 5,
      "display_name": "SSL mode",
      "documentation": "Whether to use an encrypted connection to the MySQL server. Possible settings are: `disabled`, `preferred`, and `required`. \n`disabled` specifies the use of an unencrypted connection. \n`preferred` establishes an encrypted connection if the server supports secure connections. If the server does not support secure connections, falls back to an unencrypted connection. \n`required` establishes an encrypted connection or fails if one cannot be made for any reason.",
      "recommended_values": [
        "preferred",
        "disabled",
        "required"
      ],
      "metadata": {
        "page":"AUTHENTICATION",
        "order_in_page": 5,
        "group_name": "How should we connect to your database?"
      }
    },
    {
      "name": "topic.prefix",
      "required": true,
      "documentation": "Topic prefix that provides a namespace (logical server name) for the particular MySQL database server or cluster in which Debezium is capturing changes. The prefix should be unique across all other connectors, since it is used as a topic name prefix for all Kafka topics that receive records from this connector. Only alphanumeric characters, hyphens, dots and underscores must be used. The connector automatically creates Kafka topics using the naming convention: `<topic.prefix>.<databaseName>.<tableName>`.",
      "metadata": {
        "page":"CONFIGURATION",
        "order_in_page": 6,
        "group_name": "How should we name your topic(s)?"
      }
    },
    {
      "name": "schema.history.internal.kafka.topic",
      "type": "STRING",
      "required": false,
      "default_value": "dbhistory.${topic.prefix}.{{.logicalClusterId}}",
      "importance": "HIGH",
      "group": "How should we name your topic(s)?",
      "order_in_group": 2,
      "display_name": "Database schema history topic name",
      "documentation": "The name of the topic for the database schema history. A new topic with provided name is created, if it doesn't already exist. If the topic already exists, ensure that it has a single partition, infinite retention period and is not in use by any other connector. If no value is provided, the name defaults to ``dbhistory.<topic-prefix>.<lcc-id>``.",
      "sanitizers": [
        {
          "name": "trim"
        }
      ],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 8,
        "advanced": true,
        "group_name": "How should we name your topic(s)?"
      }
    },
    {
      "name": "signal.data.collection",
      "type": "STRING",
      "required": false,
      "importance": "MEDIUM",
      "group": "Database config",
      "order_in_group": 1,
      "display_name": "Signal data collection",
      "documentation": "Fully-qualified name of the data collection that needs to be used to send signals to the connector. Use the following format to specify the fully-qualified collection name: `databaseName.tableName` ",
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 7,
        "advanced": true,
        "group_name": "Database config"
      }
    },
    {
      "name": "snapshot.mode",
      "documentation": "Specifies the criteria for running a snapshot when the connector starts. Possible settings are: `initial`, `initial_only`, `when_needed`, `never`, `schema_only`, `schema_only_recovery`. \n`initial` - the connector runs a snapshot only when no offsets have been recorded for the logical server name. \n`initial_only` - the connector runs a snapshot only when no offsets have been recorded for the logical server name and then stops; i.e. it will not read change events from the binlog. \n`when_needed` - the connector runs a snapshot upon startup whenever it deems it necessary. That is, when no offsets are available, or when a previously recorded offset specifies a binlog location or GTID that is not available in the server. \n`never` - the connector never uses snapshots. Upon first startup with a logical server name, the connector reads from the beginning of the binlog. Configure this behavior with care. It is valid only when the binlog is guaranteed to contain the entire history of the database. \n`schema_only` - the connector runs a snapshot of the schemas and not the data. This setting is useful when you do not need the topics to contain a consistent snapshot of the data but need them to have only the changes since the connector was started. \n`schema_only_recovery` - this is a recovery setting for a connector that has already been capturing changes. When you restart the connector, this setting enables recovery of a corrupted or lost database schema history topic. You might set it periodically to \"clean up\" a database schema history topic that has been growing unexpectedly. Database schema history topics require infinite retention.",
      "recommended_values": [
        "initial",
        "initial_only",
        "when_needed",
        "never",
        "schema_only",
        "schema_only_recovery"
      ],
      "validators": [
        {
          "name": "common.is.recommended.value"
        }
      ],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 11,
        "group_name": "Connector config"
      }
    },
    {
      "name": "snapshot.locking.mode",
      "type": "STRING",
      "required": false,
      "default_value": "minimal",
      "importance": "LOW",
      "group": "Connector config",
      "order_in_group": 2,
      "display_name": "Snapshot locking mode",
      "documentation": "Controls whether and how long the connector holds the global MySQL read lock, which prevents any updates to the database, while the connector is performing a snapshot. Possible settings are: `minimal`, `minimal_percona`, `extended`, and `none`. \n`minimal` - the connector holds the global read lock for just the initial portion of the snapshot, while the database schemas and other metadata are being read. The remaining work in a snapshot involves selecting all rows from each table. This is accomplished using a REPEATABLE READ transaction, even when the lock is no longer held and other MySQL clients are updating the database. \n`minimal_percona` - similar to `minimal` mode except the connector uses a (Percona-specific) backup lock. This mode does not flush tables to disk, is not blocked by long-running reads, and is available only in Percona Server. \n`extended` - blocks all writes for the duration of the snapshot. Use this setting if there are clients that are submitting operations that MySQL excludes from REPEATABLE READ semantics. \n`none` - prevents the connector from acquiring any table locks during the snapshot. While this setting is allowed with all snapshot modes, it is safe to use if and only if no schema changes are happening while the snapshot is running. For tables defined with MyISAM engine, the tables would still be locked despite this property being set as MyISAM acquires a table lock. This behavior is unlike InnoDB engine, which acquires row level locks.",
      "recommended_values": ["minimal", "minimal_percona", "extended", "none"],
      "validators": [
        {
          "name": "common.is.recommended.value"
        }
      ],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 12,
        "advanced": true,
        "group_name": "Connector config"
      }
    },
    {
      "name": "database.include.list",
      "type": "LIST",
      "required": false,
      "importance": "MEDIUM",
      "group": "Connector config",
      "order_in_group": 3,
      "display_name": "Databases included",
      "documentation": "An optional, comma-separated list of regular expressions that match the names of the databases for which to capture changes. The connector does not capture changes in any database whose name is not in this list. By default, the connector captures changes in all databases.\nTo match the name of a database, Debezium applies the regular expression that you specify as an anchored regular expression. That is, the specified expression is matched against the entire name string of the database; it does not match substrings that might be present in a database name.",
      "sanitizers": [
        {
          "name": "trim.list"
        }
      ],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 13,
        "group_name": "Connector config"
      }
    },
    {
      "name": "table.include.list",
      "order_in_group": 4,
      "documentation": "An optional, comma-separated list of regular expressions that match fully-qualified table identifiers for tables whose changes you want to capture. When this property is set, the connector captures changes only from the specified tables. Each identifier is of the form `database.tableName`. By default, the connector captures changes in every non-system table in each schema whose changes are being captured. \nTo match the name of a table, Debezium applies the regular expression that you specify as an anchored regular expression. That is, the specified expression is matched against the entire identifier for the table; it does not match substrings that might be present in a table name. \nIf you include this property in the configuration, do not also set the ``table.exclude.list`` property.",
        "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 14,
        "group_name": "Connector config"
      }
    },
    {
      "name": "table.exclude.list",
      "order_in_group": 5,
      "documentation": "An optional, comma-separated list of regular expressions that match fully-qualified table identifiers for tables whose changes you do not want to capture. Each identifier is of the form `database.tableName`. When this property is set, the connector captures changes from every table that you do not specify. \nTo match the name of a table, Debezium applies the regular expression that you specify as an anchored regular expression. That is, the specified expression is matched against the entire identifier for the table; it does not match substrings that might be present in a table name. \nIf you include this property in the configuration, do not set the ``table.include.list`` property.",
        "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 15,
        "group_name": "Connector config"
      }
    },
    {
      "name": "column.exclude.list",
      "documentation": "An optional, comma-separated list of regular expressions that match the fully-qualified names of columns to exclude from change event record values. Fully-qualified names for columns are of the form `databaseName.tableName.columnName`. \nTo match the name of a column, Debezium applies the regular expression that you specify as an anchored regular expression. That is, the specified expression is matched against the entire name string of the column; it does not match substrings that might be present in a column name.",
      "metadata": {
        "page": "CONFIGURATION",
        "advanced": true,
        "order_in_page": 15,
        "group_name": "Connector config"
      }
    },
    {
      "name": "inconsistent.schema.handling.mode",
      "type": "STRING",
      "required": false,
      "default_value": "fail",
      "importance": "MEDIUM",
      "group": "Connector config",
      "order_in_group": 10,
      "display_name": "Inconsistent schema handling mode",
      "documentation": "Specifies how the connector should react to binlog events that belong to a table missing from internal schema representation. Possible settings are: `fail`, `skip`, and `warn`. \n`fail` - throws an exception that indicates the problematic event and its binlog offset, and causes the connector to stop. \n`skip` - passes over the problematic event and does not log anything. \n`warn` - logs the problematic event and its binlog offset and skips the event.",
      "recommended_values": ["fail", "skip", "warn"],
      "validators": [
        {
          "name": "common.is.recommended.value"
        }
      ],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 20,
        "advanced": true,
        "group_name": "Connector config"
      }
    },
    {
      "name": "schema.history.internal.skip.unparseable.ddl",
      "type": "BOOLEAN",
      "required": false,
      "default_value": "false",
      "importance": "LOW",
      "group": "Connector config",
      "order_in_group": 11,
      "display_name": "Skip unparseable DDL",
      "documentation": "A Boolean value that specifies whether the connector should ignore malformed or unknown database statements (`true`), or stop processing so a human can fix the issue (`false`). Defaults to `false`. Consider setting this to `true` to ignore unparseable statements.",
      "recommended_values": ["true", "false"],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 21,
        "advanced": true,
        "group_name": "Connector config"
      }
    },
    {
      "name": "schema.history.internal.store.only.captured.tables.ddl",
      "type": "BOOLEAN",
      "required": false,
      "default_value": "false",
      "importance": "LOW",
      "group": "Connector config",
      "order_in_group": 12,
      "display_name": "Store only captured tables DDL",
      "documentation": "A Boolean value that specifies whether the connector records schema structures from all tables in a schema or database, or only from tables that are designated for capture. Defaults to `false`. \n`false` - During a database snapshot, the connector records the schema data for all non-system tables in the database, including tables that are not designated for capture. It’s best to retain the default setting. If you later decide to capture changes from tables that you did not originally designate for capture, the connector can easily begin to capture data from those tables, because their schema structure is already stored in the schema history topic. \n`true` - During a database snapshot, the connector records the table schemas only for the tables from which Debezium captures change events. If you change the default value, and you later configure the connector to capture data from other tables in the database, the connector lacks the schema information that it requires to capture change events from the tables.",
      "recommended_values": ["true", "false"],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 22,
        "advanced": true,
        "group_name": "Connector config"
      }
    },
    {
      "name": "time.precision.mode",
      "default_value": "adaptive_time_microseconds",
      "documentation": "Time, date, and timestamps can be represented with different kinds of precisions: \n`adaptive_time_microseconds` captures the date, datetime and timestamp values exactly as in the database using either millisecond, microsecond, or nanosecond precision values based on the database column’s type. An exception is `TIME` type fields, which are always captured as microseconds. \n`connect` always represents time and timestamp values by using Kafka Connect’s built-in representations for `Time`, `Date`, and `Timestamp`, which use millisecond precision regardless of the database columns' precision.",
      "recommended_values": ["adaptive_time_microseconds", "connect"],
      "validators": [
        {
          "name": "common.is.recommended.value"
        }
      ],
      "metadata": {
        "page": "CONFIGURATION",
        "order_in_page": 22,
        "advanced": true,
        "group_name": "How should we handle data types?"
      }
    }
  ],
  "connector_configs": [
    {
      "name": "schema.history.internal.kafka.topic"
    },
    {
      "name": "schema.history.internal.kafka.bootstrap.servers",
      "switch": {
        "connect.metadata_property.kafka.itsl.bootstrap.servers" : {
          "UNSET": "${kafka.endpoint}",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.bootstrap.servers}"
        }
      }
    },
    {
      "name": "schema.history.internal.consumer.ssl.trustmanager.algorithm",
      "switch": {
        "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm" : {
          "SECURED": "ConfluentTls",
          "DEFAULT": "PKIX"
        }
      }
    },
    {
      "name": "schema.history.internal.producer.ssl.trustmanager.algorithm",
      "switch": {
        "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm" : {
          "SECURED": "ConfluentTls",
          "DEFAULT": "PKIX"
        }
      }
    },
    {
      "name": "schema.history.internal.consumer.confluent.lkc.id",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc" : {
          "SKIP": "",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
        }
      }
    },
    {
      "name": "schema.history.internal.producer.confluent.lkc.id",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc" : {
          "SKIP": "",
          "DEFAULT": "${connect.metadata_property.kafka.itsl.embed.lkc}"
        }
      }
    },
    {
      "name":"schema.history.internal.consumer.confluent.proxy.protocol.client.mode",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc" : {
          "SKIP": "PROXY",
          "DEFAULT": "LOCAL"
        }
      }
    },
    {
      "name":"schema.history.internal.producer.confluent.proxy.protocol.client.mode",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc" : {
          "SKIP": "PROXY",
          "DEFAULT": "LOCAL"
        }
      }
    },
    {
      "name":"schema.history.internal.consumer.confluent.proxy.protocol.client.version",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc" : {
          "SKIP": "NONE",
          "DEFAULT": "V2"
        }
      }
    },
    {
      "name":"schema.history.internal.producer.confluent.proxy.protocol.client.version",
      "switch": {
        "connect.metadata_property.kafka.itsl.embed.lkc" : {
          "SKIP": "NONE",
          "DEFAULT": "V2"
        }
      }
    },
    {
      "name": "schema.history.internal.consumer.ssl.endpoint.identification.algorithm",
      "switch": {
        "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm" : {
          "UNSECURED_PREPROD_ONLY": "",
          "SECURED": "",
          "DEFAULT": "https"
        }
      }
    },
    {
      "name": "schema.history.internal.producer.ssl.endpoint.identification.algorithm",
      "switch": {
        "connect.metadata_property.kafka.itsl.ssl.endpoint.identification.algorithm" : {
          "UNSECURED_PREPROD_ONLY": "",
          "SECURED": "",
          "DEFAULT": "https"
        }
      }
    },
    {
      "name": "schema.history.internal.producer.sasl.jaas.config",
      "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
    },
    {
      "name": "schema.history.internal.producer.security.protocol",
      "value": "SASL_SSL"
    },
    {
      "name": "schema.history.internal.producer.sasl.mechanism",
      "value": "PLAIN"
    },
    {
      "name": "schema.history.internal.consumer.sasl.jaas.config",
      "value": "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.key}\" password=\"${file:/mnt/secrets/connect-external-secrets-{{.logicalClusterId}}.properties:kafka.api.secret}\";"
    },
    {
      "name": "schema.history.internal.consumer.security.protocol",
      "value": "SASL_SSL"
    },
    {
      "name": "schema.history.internal.consumer.sasl.mechanism",
      "value": "PLAIN"
    },
    {
      "name": "connect.timeout.ms",
      "value": "5000"
    },
    {
      "name": "schema.history.internal.kafka.recovery.poll.interval.ms",
      "value": "1000"
    },
    {
      "name": "schema.history.internal.kafka.recovery.attempts",
      "value": "100000"
    },
    {
      "name": "database.server.id",
      "value": "{{.numericClusterId}}"
    },
    {
      "name": "database.ssl.mode"
    },
    {
      "name": "database.include.list"
    },
    {
      "name": "inconsistent.schema.handling.mode"
    },
    {
      "name": "schema.history.internal.skip.unparseable.ddl"
    },
    {
      "name": "schema.history.internal.store.only.captured.tables.ddl"
    },
    {
      "name": "time.precision.mode"
    },
    {
      "name": "driver.enabledTLSProtocols",
      "value": "TLSv1.2"
    },
    {
      "name": "snapshot.locking.mode"
    },
    {
      "name": "signal.data.collection"
    },
    {
      "name": "include.schema.changes",
      "value": "false"
    }
  ]
}